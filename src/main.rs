use std::{fs, process::exit};

mod common;
mod grammar;
mod runtime;

use clap::Parser;

use crate::grammar::{lexer::Lexer, parser};

type OpacaParser = parser::Parser;

#[derive(clap::Parser, Debug)]
#[command(about, long_about = None)]
struct Args {
    /// Print the current Opaca version.
    #[arg(short, long, default_value_t = false)]
    version: bool,

    /// Show the tokens generated by the lexer.
    #[arg(short, long, default_value_t = false)]
    tokens: bool,

    /// Show the nodes generated by the parser.
    #[arg(short, long, default_value_t = false)]
    nodes: bool,

    /// The backend to use
    #[arg(short, long, default_value_t = ("interpreter").to_owned())]
    backend: String,

    rem: Vec<String>,
}

fn exit_with_msg(msg: String) -> ! {
    println!("{}", msg);
    exit(1)
}

fn main() {
    let args = Args::parse();

    if args.version {
        println!("Opaca version {}", runtime::OPACA_VERSION);
        return;
    }

    if args.rem.len() == 0 {
        exit_with_msg(String::from("no input files"));
    }

    let mut buf = String::new();

    for file in &args.rem {
        let content = match fs::read_to_string(file) {
            Ok(v) => v,
            Err(e) => {
                exit_with_msg(e.to_string());
            }
        };

        buf.push_str(&content.clone())
    }

    let mut lexer = Lexer::new(&buf);

    let tokens = match lexer.lex() {
        Ok(v) => v,
        Err(e) => {
            exit_with_msg(e.to_string());
        }
    };

    if args.tokens {
        println!("tokens:");

        for (i, token) in tokens.iter().enumerate() {
            println!(" {}: {}", i, token);
        }
    }

    let mut parser = OpacaParser::new(tokens);

    let nodes = match parser.parse() {
        Ok(v) => v,
        Err(e) => {
            exit_with_msg(e.to_string());
        }
    };

    if args.nodes {
        println!("nodes:");

        for (i, node) in nodes.iter().enumerate() {
            println!(" {}:\n{}", i, node);
        }
    }
}
